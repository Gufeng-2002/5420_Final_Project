\section{Introduction}

The SUPPORT2 dataset (available at the UCI Machine Learning Repository) contains clinical data from the Study to Understand Prognoses Preferences Outcomes and Risks of Treatment (SUPPORT), a multicenter study of hospitalized adults with life-threatening conditions.

The objectives of this project are as follows:
\begin{enumerate}
    \item To predict the \texttt{sfdm2} variable (a categorical outcome related to patient disposition after hospitalization) in the SUPPORT2 dataset.
    \item To address class imbalance using random oversampling, SMOTE (Synthetic Minority Over-sampling Technique), and an advanced prediction approach that combines SMOTE and PCA.
    \item To evaluate model performance.
\end{enumerate}

\subsection{Variable Description}
The SUPPORT2 dataset contains 10,000 records and 20 variables. The variables are categorized into three groups: 
demographic variables, admission and hospitalization details,
 and treatment and care variables.

\textbf{1. Demographic Variables}
\begin{itemize}
    \item \texttt{age}: Age of the patient (in years).
    \item \texttt{sex}: Gender of the patient (male/female).
    \item \texttt{race}: Race/ethnicity (e.g., white, black, Asian, Hispanic, etc.).
\end{itemize}

\textbf{2. Admission \& Hospitalization Details}
\begin{itemize}
    \item \texttt{hospdead}: Whether the patient died in the hospital (1 = yes, 0 = no).
    \item \texttt{d.time}: Time until death (days) or last follow-up if alive.
    \item \texttt{dzgroup}: Primary disease group (e.g., COPD, cancer, MOSF, etc.).
    \item \texttt{dzclass}: Disease class (e.g., ARF/MOSF, COPD, cancer, etc.).
    \item \texttt{num.co}: Number of comorbidities.
\end{itemize}

\textbf{3. Treatment \& Care Variables}
\begin{itemize}
    \item \texttt{ca}: Cancer status (e.g., metastatic, no cancer).
    \item \texttt{adls}: Activities of Daily Living score (functional status).
    \item \texttt{income}: Income level (categorized).
    \item \texttt{edu}: Education level (years).
    \item \texttt{sfdm2}: Patient disposition outcome after hospitalization (categorical).
\end{itemize}

\section{Literature Review}

Several papers have sought to improve classification outcomes on imbalanced datasets.

Pan et al. (2020) proposed adaptive solutions for imbalance learning using
 Adaptive and Gaussian Oversampling in extremely imbalanced datasets. 
 They developed Adaptive-SMOTE, which improves regular SMOTE by adaptively
  selecting the minority class while preserving distribution characteristics. 
  Although the study was robust due to the number of datasets used, its limitations
   include high computational complexity and reduced generalizability, especially for streaming data with dynamic imbalance ratios.

Swana et al. (2022) examined class imbalance challenges in fault classification for
 wound-rotor induction generators (WRIGs). They used SMOTE combined with Tomek links 
 (T-Link) and evaluated classifiers including Naive Bayes, SVM, and KNN. 
 Their comprehensive methodology validated performance using both simulated and experimental data.
  While their technique demonstrated strong applicability in industrial settings, 
  the study was limited to WRIGs and did not address the computational cost of SMOTE.

Mohammed (2020) tackled class imbalance in diabetes diagnosis. He combined SMOTE with 
normalization techniques (min-max, z-score, and L2 norm), using performance metrics like accuracy,
 F1-score, and precision. The study contributed the ZADA dataset and used six classifiers for comparative analysis. 
 Despite its practical significance, the dataset size was small (909 samples), collected only in Kurdistan,
  Iraq, which limits broader applicability. Additionally, there was no analysis of feature importance or discussion of clinical deployment.