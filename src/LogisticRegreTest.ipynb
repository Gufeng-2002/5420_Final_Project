{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5ff3958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12490 entries, 0 to 12489\n",
      "Data columns (total 12 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   num__avtisst                   12490 non-null  float64\n",
      " 1   num__dnrday                    12490 non-null  float64\n",
      " 2   cat_simple__dnr                12490 non-null  float64\n",
      " 3   num__adlsc                     12490 non-null  float64\n",
      " 4   num__prg6m                     12490 non-null  float64\n",
      " 5   num__adls                      12490 non-null  float64\n",
      " 6   cat_one_hot__dzgroup_COPD      12490 non-null  float64\n",
      " 7   num__sps                       12490 non-null  float64\n",
      " 8   num__aps                       12490 non-null  float64\n",
      " 9   num__hday                      12490 non-null  float64\n",
      " 10  cat_one_hot__dzclass_ARF/MOSF  12490 non-null  float64\n",
      " 11  target                         12490 non-null  float64\n",
      "dtypes: float64(12)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# read one of the filted data sets for useage\n",
    "data = pd.read_csv('../data/filtered_data/training_data_ros.csv')\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "082581c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from scipy.special import expit  # More stable sigmoid function\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496c0c8c",
   "metadata": {},
   "source": [
    "## Initial version: binomial classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3c800a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Custom feature transformation\n",
    "def trans_matrix_for_splines(X):\n",
    "    # X is (n_samples, 9)\n",
    "    # Example: add squared terms for nonlinear regression\n",
    "    X_squared = X ** 2\n",
    "    intercept = np.ones((X.shape[0], 1))\n",
    "    return np.hstack([intercept, X, X_squared])\n",
    "\n",
    "# Logistic loss function (negative log-likelihood)\n",
    "def average_likelihood_fn(beta, X, y):\n",
    "    \n",
    "    # z for linear prediction of logit transformed probability being 1\n",
    "    z = X @ beta\n",
    "    \n",
    "    # p for predicted probability of y being 1\n",
    "    p = sigmoid(z) # a function of X and beta\n",
    "    \n",
    "    # given data and beta, the likelihood of this beta value is \n",
    "    epsilon = 1e-9 # to avoid log(0)\n",
    "    neg_likelihood_beta = -np.mean(y * np.log(p + epsilon) + (1 - y) * np.log(1 - p + epsilon))\n",
    "    return neg_likelihood_beta # the beta that minimizes this is the best fit on the given data\n",
    "\n",
    "# Fit model\n",
    "def fit_logistic(X, y):\n",
    "    \n",
    "    # transform/map the design matrix to a higher dimentional space for splines\n",
    "    X_transformed = trans_matrix_for_splines(X)\n",
    "    \n",
    "    # set an initial value to beta vector (0 for now)\n",
    "    beta_init = np.zeros(X_transformed.shape[1])\n",
    "    \n",
    "    # using optimization function from scipy to minimize the negative log-likelihood\n",
    "    result = minimize(average_likelihood_fn, beta_init, args=(X_transformed, y), method='BFGS')\n",
    "    \n",
    "    # return MLE beta (average likelihood function minimized)\n",
    "    mle_beta = result.x\n",
    "    return mle_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5806178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True beta (first 10): [ 0.5     0.8    -0.4     0.2667 -0.2     0.16   -0.1333  0.1143 -0.1\n",
      "  0.0889]\n",
      "Estimated beta (first 10): [ 0.517   1.0153 -0.3586  0.3572 -0.1673  0.0607 -0.0186  0.1453 -0.1212\n",
      "  0.0313]\n"
     ]
    }
   ],
   "source": [
    "# test the above functions on a simulation data \n",
    "# Simulate data\n",
    "def simulate_logistic_data(n_samples=500, n_features=9, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Simulate predictors X\n",
    "    X = np.random.normal(0, 1, size=(n_samples, n_features))\n",
    "    \n",
    "    # True beta (including intercept)\n",
    "    true_beta = np.array([0.5] + [(-1)**i * 0.8 / (i+1) for i in range(n_features * 2)])  # length = 1 + 2*n_features\n",
    "    \n",
    "    # Transform X for splines: includes intercept, X, and X^2\n",
    "    X_transformed = trans_matrix_for_splines(X)\n",
    "    \n",
    "    # Compute probabilities using logistic model\n",
    "    logits = X_transformed @ true_beta\n",
    "    probs = expit(logits)\n",
    "    \n",
    "    # Simulate binary outcome\n",
    "    y = np.random.binomial(1, probs)\n",
    "    \n",
    "    return X, y, true_beta\n",
    "\n",
    "# --- Example usage ---\n",
    "X_sim, y_sim, beta_true = simulate_logistic_data()\n",
    "estimated_beta = fit_logistic(X_sim, y_sim)\n",
    "\n",
    "print(\"True beta (first 10):\", np.round(beta_true[:10], 4))\n",
    "print(\"Estimated beta (first 10):\", np.round(estimated_beta[:10], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ed862",
   "metadata": {},
   "source": [
    "### Waiting to be checked below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a0307c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waiting for the one-vs-rest logistic regression function to be implemented\n",
    "# fit one-vs-rest logistic regression for multiclass classification\n",
    "def fit_multiclass_logistic_ovr(X, y, num_classes):\n",
    "    models = {}\n",
    "    for cls in range(num_classes):\n",
    "        y_binary = (y == cls).astype(int)  # One-vs-Rest\n",
    "        beta = fit_logistic(X, y_binary)   # Use your earlier function\n",
    "        models[cls] = beta\n",
    "    return models\n",
    "\n",
    "# Predict for multiclass\n",
    "def predict_multiclass(X, models):\n",
    "    X_transformed = trans_matrix_for_splines(X)\n",
    "    probs = {}\n",
    "    for cls, beta in models.items():\n",
    "        probs[cls] = sigmoid(X_transformed @ beta)\n",
    "    \n",
    "    # Combine predictions into a matrix (n_samples x num_classes)\n",
    "    prob_matrix = np.vstack([probs[cls] for cls in sorted(probs.keys())]).T\n",
    "    return np.argmax(prob_matrix, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883aeaea",
   "metadata": {},
   "source": [
    "## Version 2: transform X to a new design matrix for splines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630c2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc7e613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom design matrix mapping function\n",
    "def truncated_power(x, knot, degree):\n",
    "    return np.where(x > knot, (x - knot) ** degree, 0.0)\n",
    "\n",
    "def transform_column_with_splines(x_col, degree=3, knots=None, include_intercept=False):\n",
    "    \"\"\"\n",
    "    Transform a single column using spline basis expansion.\n",
    "    \"\"\"\n",
    "    base = [x_col**d for d in range(1, degree + 1)]\n",
    "    if include_intercept:\n",
    "        base = [np.ones_like(x_col)] + base\n",
    "    if knots:\n",
    "        for knot in knots:\n",
    "            base.append(truncated_power(x_col, knot, degree))\n",
    "    return np.column_stack(base)\n",
    "\n",
    "def transform_matrix_with_splines(X, knots_dict = None, degree=3, include_intercept=False):\n",
    "    \"\"\"\n",
    "    Apply spline transformation to all columns in X with different knots per column.\n",
    "\n",
    "    Args:\n",
    "        X: (n, p) input matrix\n",
    "        knots_dict: dict mapping column index to list of knots for that column\n",
    "        degree: spline degree (default = 3 for cubic)\n",
    "        include_intercept: whether to include an intercept term per column (default = False)\n",
    "\n",
    "    Returns:\n",
    "        Transformed design matrix (n, ?)\n",
    "    \"\"\"\n",
    "    X = np.asarray(X)\n",
    "    n, p = X.shape\n",
    "    transformed_columns = []\n",
    "    \n",
    "    # Transform X for splines with transform_matrix_with_splines : includes intercept,\n",
    "    quantile_knots = [0.25, 0.5, 0.75]    # assuming columns have been standardized\n",
    "\n",
    "    knots_dict = {\n",
    "       i: quantile_knots for i in range(X.shape[1])\n",
    "    }\n",
    "\n",
    "    for j in range(p):\n",
    "        x_col = X[:, j]\n",
    "        knots = knots_dict.get(j, [])  # empty if not specified\n",
    "        X_j_spline = transform_column_with_splines(x_col, degree, knots, include_intercept)\n",
    "        transformed_columns.append(X_j_spline)\n",
    "\n",
    "    return np.hstack(transformed_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550b8a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the above functions on a simulation data \n",
    "# Simulate data\n",
    "def simulate_logistic_data(n_samples=500, n_features=15, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    # Simulate predictors X\n",
    "    X = np.random.normal(0, 1, size=(n_samples, n_features))\n",
    "    \n",
    "    # Transform X for splines with transform_matrix_with_splines : includes intercept,\n",
    "    # quantile_knots = [0.25, 0.5, 0.75]    # assuming columns have been standardized\n",
    "\n",
    "    # knots_dict = {\n",
    "    #    i: quantile_knots for i in range(X.shape[1])\n",
    "    # }\n",
    "    \n",
    "    X_transformed = transform_matrix_with_splines(X, degree = 2, include_intercept=True)\n",
    "    \n",
    "    transformed_n_features = X_transformed.shape[1]\n",
    "    print(\"Transformed shape:\", X_transformed.shape)\n",
    "    \n",
    "    # True beta (including intercept)\n",
    "    true_beta = np.array([(-1)**i * 0.8 / (i+1) for i in range(transformed_n_features)])  # length = # of transformed_n_features\n",
    "    print(\"True beta shape:\", true_beta.shape)\n",
    "    \n",
    "    \n",
    "    # Compute probabilities using logistic model\n",
    "    logits = X_transformed @ true_beta\n",
    "    probs = expit(logits)\n",
    "    \n",
    "    # Simulate binary outcome\n",
    "    y = np.random.binomial(1, probs)\n",
    "    \n",
    "    return X, y, true_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3aa2805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed shape: (500, 90)\n",
      "True beta shape: (90,)\n",
      "True beta (first 10): [ 0.8    -0.4     0.2667 -0.2     0.16   -0.1333  0.1143 -0.1     0.0889\n",
      " -0.08  ]\n",
      "Estimated beta (first 10): [-0.2339 -0.3019 -0.048  -0.1609 -0.0775 -0.0187 -0.1425 -0.0806 -0.128\n",
      "  0.0913]\n"
     ]
    }
   ],
   "source": [
    "# change the knots to check \n",
    "import LogsiticRegre as lr\n",
    "X_sim, y_sim, beta_true = simulate_logistic_data()\n",
    "transformed_x_sim = lr.transform_matrix_with_splines(X_sim, degree=3, include_intercept=True)\n",
    "estimated_beta = lr.fit_logistic(X_sim, y_sim)\n",
    "\n",
    "print(\"True beta (first 10):\", np.round(beta_true[:10], 4))\n",
    "print(\"Estimated beta (first 10):\", np.round(estimated_beta[:10], 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0349853",
   "metadata": {},
   "source": [
    "## Version 3: Estimate prior for beta vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4505da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
